{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running as docker?\n",
    "docker_running = False\n",
    "\n",
    "# define repo path and add it to the path\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "if not docker_running: # if we are running locally\n",
    "    repo_path= Path.cwd().resolve()\n",
    "    while '.gitignore' not in os.listdir(repo_path): # while not in the root of the repo\n",
    "        repo_path = repo_path.parent #go up one level\n",
    "else: # if running in the container\n",
    "    repo_path = Path('opt/usuari')\n",
    "sys.path.insert(0,str(repo_path)) if str(repo_path) not in sys.path else None\n",
    "\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    InterpolationMode,\n",
    ")\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "\n",
    "# special imports\n",
    "from segmentation import USSegmentation\n",
    "from datasets_utils.datasets import ABUS_test\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to understand is that each image will need to store 64 MB of slices.<br>\n",
    "Thus images will be stored along other cache information in the cached_data folder.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lesion_seg:\n",
    "    def __init__(self):\n",
    "        self.input_dir = Path('./input/') if docker_running else repo_path / 'input'\n",
    "        self.output_dir = Path('./predict') / 'Segmentation' if docker_running else Path(repo_path / 'predict' / 'Segmentation')\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True) # make sure the output dir exists\n",
    "        self.checkpoint_dir = repo_path / 'checkpoints' / 'sam_vit_b_01ec64.pth'\n",
    "        self.cached_dir = repo_path / 'cached_data'\n",
    "        self.cached_dir.mkdir(parents=True, exist_ok=True) # create cached dir in root\n",
    "        self.slices_dir = self.cached_dir / 'slices'\n",
    "        self.probs_dir = self.cached_dir / 'probs'\n",
    "        # load all folds models\n",
    "        self.md = USSegmentation(self.checkpoint_dir)\n",
    "        load_success = self.md.load_model()\n",
    "        if load_success:\n",
    "            print(\"Successfully loaded models\")\n",
    "\n",
    "    def save_slices(self, image_path:Path):\n",
    "        \"\"\"given an nrrd image path, the slices are saved in the cached_dir/slices folder\n",
    "\n",
    "        Args:\n",
    "            image_path (Path): Path to the nrrd image\n",
    "        \"\"\"\n",
    "        # Expansion HP\n",
    "        x_expansion = 865\n",
    "        y_expansion = 865\n",
    "        x_resizing = 512\n",
    "        y_resizing = 512\n",
    "        file_format = 'mha'\n",
    "\n",
    "\n",
    "        # remove folder if exists, always starts from scratch\n",
    "        if self.slices_dir.exists():\n",
    "            shutil.rmtree(self.slices_dir)\n",
    "        self.slices_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        # transforms\n",
    "        preprocess_im = Compose(\n",
    "                [\n",
    "                    Resize((x_resizing, y_resizing), interpolation= InterpolationMode.BILINEAR),\n",
    "                ]\n",
    "        )\n",
    "\n",
    "        # get image\n",
    "        im_sitk = sitk.ReadImage(image_path)\n",
    "        shape = im_sitk.GetSize()\n",
    "        im = sitk.GetArrayFromImage(im_sitk)\n",
    "        # now, we complete the images and labels to the expansion variables\n",
    "        if im.shape[2]<x_expansion:\n",
    "            # print('Expanding x dimension')\n",
    "            im = np.concatenate((im, np.zeros((im.shape[0], im.shape[1], x_expansion-im.shape[2]), dtype=np.int8)), axis=2)\n",
    "\n",
    "        if im.shape[1]<y_expansion:\n",
    "            # print('Expanding y dimension')\n",
    "            im = np.concatenate((im, np.zeros((im.shape[0], y_expansion-im.shape[1], im.shape[2]), dtype=np.int8)), axis=1)\n",
    "\n",
    "        # all z values available\n",
    "        z_values = np.array(range(im.shape[0]))\n",
    "        for z in tqdm(z_values):\n",
    "            # preprocess image\n",
    "            im_slice = Image.fromarray(im[z])\n",
    "            im_slice = preprocess_im(im_slice)\n",
    "            im_slice = np.asarray(im_slice)\n",
    "            # put channel first and repeat in RGB\n",
    "            im_slice = np.repeat(np.expand_dims(im_slice, axis=0), 3, axis=0)\n",
    "\n",
    "            # saving path\n",
    "            save_name = f'slice_{z}.{file_format}'\n",
    "            # save image\n",
    "            sitk.WriteImage(sitk.GetImageFromArray(im_slice), str(self.slices_dir / save_name))\n",
    "        \n",
    "        return shape\n",
    "\n",
    "    def prob_map(self, image_path:Path):\n",
    "        \"\"\"create a probability map for a given image path\n",
    "\n",
    "        Args:\n",
    "            image_path (Path): path of the nrrd original image\n",
    "        \"\"\"\n",
    "        original_shape = self.save_slices(image_path) # save slices and get original shape\n",
    "        prob_map = self.md.process_image(slices_dir=self.slices_dir, original_shape=original_shape)\n",
    "        # save the prob map as numpy array\n",
    "        np.save(self.probs_dir / 'prob_map.npy', prob_map)\n",
    "\n",
    "    # def seed_definition():\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded on CUDA\n",
      "Successfully loaded models\n"
     ]
    }
   ],
   "source": [
    "segmenter = lesion_seg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ricardo/ABUS2023_documents/tdsc_abus23/input/DATA_101.nrrd')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = list(segmenter.input_dir.glob(\"*\"))\n",
    "image_path = image_paths[0]\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 348/348 [00:02<00:00, 129.36it/s]\n",
      "Processing slices: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n",
      "Processing slices: 100%|██████████| 11/11 [00:10<00:00,  1.10it/s]\n",
      "Processing slices: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s]\n",
      "Processing slices: 100%|██████████| 11/11 [00:10<00:00,  1.08it/s]\n",
      "Processing slices: 100%|██████████| 11/11 [00:10<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the accumulated mask is torch.Size([348, 2, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 348/348 [00:01<00:00, 281.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the final output is (348, 682, 865)\n"
     ]
    }
   ],
   "source": [
    "segmenter.prob_map(image_path=image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore examples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abus_h",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
