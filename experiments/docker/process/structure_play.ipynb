{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running as docker?\n",
    "docker_running = False\n",
    "\n",
    "# define repo path and add it to the path\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "if not docker_running: # if we are running locally\n",
    "    repo_path= Path.cwd().resolve()\n",
    "    while '.gitignore' not in os.listdir(repo_path): # while not in the root of the repo\n",
    "        repo_path = repo_path.parent #go up one level\n",
    "else: # if running in the container\n",
    "    repo_path = Path('opt/usuari')\n",
    "sys.path.insert(0,str(repo_path)) if str(repo_path) not in sys.path else None\n",
    "\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Resize,\n",
    "    InterpolationMode,\n",
    ")\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "\n",
    "# special imports\n",
    "from segmentation import USSegmentation\n",
    "from datasets_utils.datasets import ABUS_test\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to understand is that each image will need to store 64 MB of slices.<br>\n",
    "Thus images will be stored along other cache information in the cached_data folder.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lesion_seg:\n",
    "    def __init__(self):\n",
    "        self.input_dir = Path('./input/') if docker_running else repo_path / 'input'\n",
    "        self.output_dir = Path('./predict') / 'Segmentation' if docker_running else Path(repo_path / 'predict' / 'Segmentation')\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True) # make sure the output dir exists\n",
    "        self.checkpoint_dir = repo_path / 'checkpoints' / 'sam_vit_b_01ec64.pth'\n",
    "        self.cached_dir = repo_path / 'cached_data'\n",
    "        self.cached_dir.mkdir(parents=True, exist_ok=True) # create cached dir in root\n",
    "        self.slices_dir = self.cached_dir / 'slices'\n",
    "        # load all folds models\n",
    "        self.md = USSegmentation(self.checkpoint_dir)\n",
    "        load_success = self.md.load_model()\n",
    "        if load_success:\n",
    "            print(\"Successfully loaded models\")\n",
    "\n",
    "    def save_slices(self, image_path:Path):\n",
    "        \"\"\"given an nrrd image path, the slices are saved in the cached_dir/slices folder\n",
    "\n",
    "        Args:\n",
    "            image_path (Path): Path to the nrrd image\n",
    "        \"\"\"\n",
    "        # Expansion HP\n",
    "        x_expansion = 865\n",
    "        y_expansion = 865\n",
    "        x_resizing = 512\n",
    "        y_resizing = 512\n",
    "        file_format = 'mha'\n",
    "\n",
    "\n",
    "        # remove folder if exists, always starts from scratch\n",
    "        if self.slices_dir.exists():\n",
    "            shutil.rmtree(self.slices_dir)\n",
    "        self.slices_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        # transforms\n",
    "        preprocess_im = Compose(\n",
    "                [\n",
    "                    Resize((x_resizing, y_resizing), interpolation= InterpolationMode.BILINEAR),\n",
    "                ]\n",
    "        )\n",
    "\n",
    "        # get image\n",
    "        im_sitk = sitk.ReadImage(image_path)\n",
    "        shape = im_sitk.GetSize()\n",
    "        im = sitk.GetArrayFromImage(im_sitk)\n",
    "        # now, we complete the images and labels to the expansion variables\n",
    "        if im.shape[2]<x_expansion:\n",
    "            # print('Expanding x dimension')\n",
    "            im = np.concatenate((im, np.zeros((im.shape[0], im.shape[1], x_expansion-im.shape[2]), dtype=np.int8)), axis=2)\n",
    "\n",
    "        if im.shape[1]<y_expansion:\n",
    "            # print('Expanding y dimension')\n",
    "            im = np.concatenate((im, np.zeros((im.shape[0], y_expansion-im.shape[1], im.shape[2]), dtype=np.int8)), axis=1)\n",
    "\n",
    "        # all z values available\n",
    "        z_values = np.array(range(im.shape[0]))\n",
    "        for z in tqdm(z_values):\n",
    "            # preprocess image\n",
    "            im_slice = Image.fromarray(im[z])\n",
    "            im_slice = preprocess_im(im_slice)\n",
    "            im_slice = np.asarray(im_slice)\n",
    "            # put channel first and repeat in RGB\n",
    "            im_slice = np.repeat(np.expand_dims(im_slice, axis=0), 3, axis=0)\n",
    "\n",
    "            # saving path\n",
    "            save_name = f'slice_{z}.{file_format}'\n",
    "            # save image\n",
    "            sitk.WriteImage(sitk.GetImageFromArray(im_slice), str(self.slices_dir / save_name))\n",
    "        \n",
    "        return shape\n",
    "\n",
    "    # def prob_map():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded on CUDA\n",
      "Successfully loaded models\n"
     ]
    }
   ],
   "source": [
    "segmenter = lesion_seg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ricardo/ABUS2023_documents/tdsc_abus23/input/DATA_101.nrrd')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = list(segmenter.input_dir.glob(\"*\"))\n",
    "image_path = image_paths[0]\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 348/348 [00:02<00:00, 128.11it/s]\n"
     ]
    }
   ],
   "source": [
    "original_shape = segmenter.save_slices(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the probability map must be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(self, input_image):\n",
    "    image = self.test_transform({\"image\": input_image})[\"image\"]\n",
    "    image = image.to(device=self.device).unsqueeze(0)\n",
    "    input_h_flipped = self.h_flip(image)\n",
    "    final_output = torch.zeros((1, 4, 256, 256), dtype=torch.float32).to(self.device)\n",
    "    for i in range(5):\n",
    "        self.models[i].eval()\n",
    "        outputs = self.models[i](image, True, 256)\n",
    "        outputs_h_flip = self.models[i](input_h_flipped, True, 256)\n",
    "\n",
    "        output_masks_t = (outputs['masks'] + self.h_flip(outputs_h_flip['masks'])) / 2\n",
    "        final_output += output_masks_t\n",
    "\n",
    "    output_masks = torch.argmax(torch.softmax(final_output / 5, dim=1), dim=1, keepdim=True)\n",
    "\n",
    "    return output_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of slices is 350\n"
     ]
    }
   ],
   "source": [
    "# get all files in the folder in a list, only mha files\n",
    "slice_files = [file for file in os.listdir(segmenter.slices_dir) if file.endswith('.mha')] # unordered files\n",
    "slice_files = sorted(slice_files, key=lambda x: int(x.split('.')[0].split('_')[1]))\n",
    "\n",
    "# create final paths\n",
    "image_files = np.array([segmenter.slices_dir / i for i in slice_files])\n",
    "db_val = ABUS_test(transform=segmenter.md.test_transform,list_dir=image_files)   \n",
    "valloader = DataLoader(db_val, batch_size=32, shuffle=False, num_workers=12, pin_memory=True)\n",
    "print(f'The number of slices is {len(db_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:10<00:00,  1.03it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.03it/s]\n",
      "100%|██████████| 11/11 [00:11<00:00,  1.00s/it]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.02it/s]\n",
      "100%|██████████| 11/11 [00:11<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the accumulated mask is torch.Size([350, 2, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "num_classes = segmenter.md.num_classes\n",
    "image_size = segmenter.md.image_size\n",
    "device = segmenter.md.device\n",
    "\n",
    "# 2. Create probability volume\n",
    "accumulated_mask = torch.zeros((len(db_val),num_classes+1,image_size,image_size)) # store final mask per patient\n",
    "\n",
    "for model in segmenter.md.models: # for each model learned\n",
    "\n",
    "    model_mask = [] # for appending slices of same model\n",
    "    for sample_batch in tqdm(valloader):\n",
    "        with torch.no_grad():\n",
    "            # get data\n",
    "            image_batch = sample_batch[\"image\"].to(device)\n",
    "            # forward and losses computing\n",
    "            outputs = model(image_batch, True, image_size)\n",
    "            # stack the masks\n",
    "            model_mask.append(outputs['masks'].detach().cpu())\n",
    "    # stack tensors in a single one\n",
    "    model_mask = torch.cat(model_mask, dim=0)\n",
    "    accumulated_mask += model_mask\n",
    "print(f'The shape of the accumulated mask is {accumulated_mask.shape}')\n",
    "\n",
    "# get the mean\n",
    "accumulated_mask /= len(segmenter.md.models)\n",
    "accumulated_mask = torch.softmax(accumulated_mask, dim=1)[:,1] # get lesion probability\n",
    "accumulated_mask = accumulated_mask.cpu().numpy()\n",
    "\n",
    "# reshape each slice\n",
    "x_expansion = 865\n",
    "y_expansion = 865\n",
    "resized_mask = []\n",
    "for slice_num in tqdm(range(accumulated_mask.shape[0])):\n",
    "    im_slice = accumulated_mask[slice_num,:,:]\n",
    "    im_slice = Image.fromarray(im_slice)\n",
    "    im_slice_comeback = torchvision.transforms.Resize(\n",
    "        (x_expansion, y_expansion),\n",
    "        interpolation= torchvision.transforms.InterpolationMode.BILINEAR, # bilineal or nearest? probs bilineal\n",
    "        )(im_slice)\n",
    "    resized_mask.append(im_slice_comeback)\n",
    "# stack all slices\n",
    "resized_mask = np.stack(resized_mask, axis=0)\n",
    "# get original size and save\n",
    "final_mask = resized_mask[:,:original_shape[1],:original_shape[0]]\n",
    "print(f'The shape of the final output is {final_mask.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [00:01<00:00, 316.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the resized mask is (350, 865, 865)\n",
      "The shape of the final output is (350, 682, 865)\n"
     ]
    }
   ],
   "source": [
    "saving_path = saving_dir  / f'MASK_{pat_id}.nii.gz'\n",
    "\n",
    "# save the mask as nii.gz\n",
    "sitk.WriteImage(sitk.GetImageFromArray(final_mask), str(saving_path), True, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abus_h",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
