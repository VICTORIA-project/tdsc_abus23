{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# this data loader is in a file now\n",
    "class Abus23DataLoader():\n",
    "    def __init__(self, dataset_path, labels_csv=None):\n",
    "        self.data = self.load_abus23(dataset_path, labels_csv)\n",
    "        self.dataset_path = dataset_path\n",
    "        self.used_data = self.data\n",
    "        self.cidx = 0\n",
    "        \n",
    "    def load_abus23(self, dataset_path, label_file=None):\n",
    "        if label_file is not None:\n",
    "            dataset = pd.read_csv(os.path.join(dataset_path, label_file))\n",
    "        else:\n",
    "            files = [f for f in os.listdir(dataset_path) if f.endswith(\".nrrd\")]\n",
    "            files_id = [int(f.split(\".\")[0].split(\"_\")[-1]) for f in files]\n",
    "            files_path = [f for f in files] #os.path.join(dataset_path, f) \n",
    "            dataset_dict = [{\"case_id\": f_id, \"data_path\": f_path} for f_id, f_path in zip(files_id, files_path)]\n",
    "            dataset = pd.DataFrame.from_dict(dataset_dict)\n",
    "        print(\"Dataset columns:\", dataset.columns)\n",
    "        return dataset\n",
    "    \n",
    "    def set_subset_ids(self, list_id = [], id_label = 'case_id'):\n",
    "        if list_id:\n",
    "            self.used_data = self.data[self.data[id_label].isin(list_id)]\n",
    "        \n",
    "    def get_data_entry(self, idx):    \n",
    "        return self.used_data.iloc[idx]\n",
    "    \n",
    "    def get_item(self, idx):\n",
    "        entry = self.get_data_entry(idx).to_dict()\n",
    "        output = {}\n",
    "        output[\"id\"] = entry['case_id']\n",
    "        if 'label' in entry:\n",
    "            output[\"class\"] =entry['label']\n",
    "        image_full_path = os.path.join(self.dataset_path, entry['data_path'].replace('\\\\','/'))\n",
    "        output[\"image\"] = sitk.ReadImage(image_full_path)\n",
    "        output[\"image_path\"] = image_full_path\n",
    "        if 'mask_path' in entry:\n",
    "            mask_full_path = os.path.join(self.dataset_path, entry['mask_path'].replace('\\\\','/'))\n",
    "            output[\"mask\"] = sitk.ReadImage(mask_full_path)\n",
    "            output[\"mask_path\"] = mask_full_path\n",
    "            \n",
    "        return output\n",
    "\n",
    "    def get_keys(self):\n",
    "        return self.used_data.columns.tolist()\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "       return self.get_item(idx)\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.used_data)\n",
    "   \n",
    "def get_validation_ids(val_file):\n",
    "    with open(val_file) as fp:\n",
    "        lines = fp.readlines()\n",
    "        #print([os.path.basename(i)for i in lines])\n",
    "        patients = set([int(os.path.basename(case).split('_')[0]) for case in lines])\n",
    "    return list(patients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def normalize_8bits(image: np.ndarray):\n",
    "    return (255.0 *(image - image.min()) / (image.max() - image.min())).astype(np.uint8)\n",
    "\n",
    "def get_slices(data, norm_fn = normalize_8bits):\n",
    "    data_array = sitk.GetArrayFromImage(data)\n",
    "    return [norm_fn(data_array[i, ...]) for i in range(len(data_array))]\n",
    "\n",
    "\n",
    "# Create the volume from slices\n",
    "\n",
    "def volume_from_slice(slices, format=None):\n",
    "    mask_3d = np.stack(slices)\n",
    "    output_mask = sitk.GetImageFromArray(mask_3d)\n",
    "    \n",
    "    if format is not None:\n",
    "        #sitk.GetPixelIDValueAsString(format)\n",
    "        castImageFilter = sitk.CastImageFilter()\n",
    "        castImageFilter.SetOutputPixelType(format)\n",
    "        output_mask = castImageFilter.Execute(output_mask)\n",
    "        \n",
    "    return output_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load a model\n",
    "class YOLOPredictor:\n",
    "    def __init__(self, model_file, conf_th = 0.5):\n",
    "        self.model = YOLO(model_file)  # pretrained YOLOv8n model\n",
    "        self.conf_th = conf_th\n",
    "        \n",
    "    def set_conf_th(self, conf_th = 0.5):\n",
    "        self.conf_th = conf_th\n",
    "        \n",
    "    def __call__(self, slice, conf_th=None):\n",
    "        return self.predict(slice, conf_th)\n",
    "        \n",
    "    def predict(self, slice, conf_th=None):\n",
    "        assert len(slice.shape) == 2\n",
    "        \n",
    "        if conf_th is None:\n",
    "            conf_th = self.conf_th\n",
    "        \n",
    "        cv2.imwrite(\"temp.png\", slice)\n",
    "        results = self.model(\"temp.png\", verbose=False)[0].cpu().numpy()\n",
    "        \n",
    "        slice_mask = np.zeros(slice.shape)\n",
    "        if results.masks is not None:\n",
    "            \n",
    "            pred_mask_data = results.masks.data\n",
    "            for i in range(len(pred_mask_data)):\n",
    "                \n",
    "                pred_box_conf = results.boxes[i].conf  # confidence score, (N, )\n",
    "                if pred_box_conf < conf_th:\n",
    "                    continue\n",
    "\n",
    "                m = cv2.resize(pred_mask_data[i, ...], dsize=(slice.shape[1], slice.shape[0])) # interpolation=cv2.INTER_CUBIC)\n",
    "                slice_mask = np.logical_or(slice_mask, m).astype(\"float32\")\n",
    "                \n",
    "        return slice_mask       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns: Index(['case_id', 'data_path'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [08:50<00:00, 17.68s/it]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ABUS 23\n",
    "dataset_path = \"datasets/DATA\"\n",
    "label_file = None #\"labels.csv\"\n",
    "validation_file = None #\"datasets/abus23_25_png/val_seg.txt\"\n",
    "\n",
    "# Yolo model\n",
    "yolo_weights = \"/home/joel/abus23/runs/segment/train10/weights/best.pt\"\n",
    "\n",
    "# Volume\n",
    "confidance_th = 0.6\n",
    "\n",
    "# Output folder\n",
    "output_folder = os.path.join(\"results_masks\", \"abus23_test\", \"raw_stack_train10\")\n",
    "output_file_template = \"MASK_{:0>3}.nii.gz\"\n",
    "output_format = sitk.sitkUInt8\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(output_folder, exist_ok=False)\n",
    "\n",
    "# Load dataset\n",
    "dataset = Abus23DataLoader(dataset_path, label_file)\n",
    "\n",
    "# Get validation cases\n",
    "if validation_file is not None:\n",
    "        val_ids = get_validation_ids(validation_file)\n",
    "        dataset.set_subset_ids(val_ids)\n",
    "\n",
    "# Load yolo predictor\n",
    "yolo_predictor = YOLOPredictor(yolo_weights)\n",
    "\n",
    "# For each item in the dataset\n",
    "gt_files = []\n",
    "pred_files = []\n",
    "for item in tqdm(dataset):\n",
    "    \n",
    "        # Get image slice\n",
    "        image_slices = get_slices(item['image'])\n",
    "\n",
    "        # Get predicted slices\n",
    "        yolo_masks_slices = [yolo_predictor(slice, conf_th=confidance_th) for slice in image_slices]\n",
    "\n",
    "        # Create 3D volum\n",
    "        mask_volum = volume_from_slice(yolo_masks_slices, output_format)               \n",
    "        \n",
    "        # Copy metadata from predited image\n",
    "        mask_volum.CopyInformation(item['image'])\n",
    "        \n",
    "        # Save NRRD mask prediction\n",
    "        mask_file = os.path.join(output_folder, output_file_template.format(item['id']))\n",
    "        sitk.WriteImage(mask_volum, mask_file, useCompression=True )\n",
    "        \n",
    "        # Save file names for evaluation\n",
    "        pred_files.append(mask_file)\n",
    "        if 'mask_path' in item:\n",
    "                gt_files.append(item['mask_path'])\n",
    "                \n",
    "if len(gt_files) > 0:\n",
    "        with open(os.path.join(output_folder,\"cases.json\"), \"w\") as fp:\n",
    "                json.dump({\"gt_files\": gt_files,\n",
    "                        \"pred_files\": pred_files,\n",
    "                        \"confidance_th\": confidance_th},fp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TDSCABUS2023.Metrics import segmentation\n",
    "\n",
    "\n",
    "def Validate(pred_list, gt_list, cvs_pred_file = None, csv_gt_file = None):\n",
    "    \n",
    "    print(\"Segmentation:\")\n",
    "    print(\"------------------------------------------\")\n",
    "    \n",
    "    scores = {'DiceCoefficient': [], 'HDCoefficient': [], 'score': []}\n",
    "    for pred, gt in zip(pred_list, gt_list):\n",
    "        try:\n",
    "            result = segmentation.score_case(gt, pred)\n",
    "        except Exception as e:\n",
    "           result = {'DiceCoefficient': 0, 'HDCoefficient': 0, 'score': 0} #HD coefficient if fail?\n",
    "        print(\"Case:\", os.path.basename(pred), \"  Results:\",  result)\n",
    "        \n",
    "        for k, v in result.items():\n",
    "            scores[k].append(v)\n",
    "        \n",
    "    for k, values in scores.items():\n",
    "        values = np.array(values)\n",
    "        print(f\"\\n{k}:\")\n",
    "        print(f\"   - Min: {values.min():0.4f}\")\n",
    "        print(f\"   - Max: {values.max():0.4f}\")\n",
    "        print(f\"   - Mean: {values.mean():0.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['results_masks/abus23_test/raw_stack_train10/MASK_107.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_109.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_105.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_127.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_116.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_118.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_119.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_115.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_101.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_124.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_128.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_126.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_104.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_108.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_117.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_106.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_129.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_111.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_102.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_100.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_122.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_110.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_123.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_112.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_103.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_114.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_120.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_125.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_113.nii.gz', 'results_masks/abus23_test/raw_stack_train10/MASK_121.nii.gz']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "gt_files = [g.replace(\"DATA\", \"MASK\") for g in gt_files]\n",
    "print(pred_files)\n",
    "print(gt_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating.. (Conf: 0.6)\n",
      "Segmentation:\n",
      "------------------------------------------\n",
      "\n",
      "DiceCoefficient:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m         confidance_th \u001b[39m=\u001b[39m json_data[\u001b[39m\"\u001b[39m\u001b[39mconfidance_th\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValidating.. (Conf: \u001b[39m\u001b[39m{\u001b[39;00mconfidance_th\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m Validate(pred_files, gt_files)\n",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m, in \u001b[0;36mValidate\u001b[0;34m(pred_list, gt_list, cvs_pred_file, csv_gt_file)\u001b[0m\n\u001b[1;32m     21\u001b[0m values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(values)\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m   - Min: \u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m.\u001b[39;49mmin()\u001b[39m:\u001b[39;00m\u001b[39m0.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m   - Max: \u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m.\u001b[39mmax()\u001b[39m:\u001b[39;00m\u001b[39m0.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m   - Mean: \u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m.\u001b[39mmean()\u001b[39m:\u001b[39;00m\u001b[39m0.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/abus23/py_env/py310_1/lib/python3.10/site-packages/numpy/core/_methods.py:44\u001b[0m, in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_amin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m           initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[39mNone\u001b[39;49;00m, out, keepdims, initial, where)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "if \"gt_files\" not in locals() or \"pred_files\" not in locals():\n",
    "    if not os.path.exists(os.path.join(output_folder,\"cases.json\")):\n",
    "        print(f\"Data not found in {output_folder}\")\n",
    "    print(f\"Loading data from {output_folder}..\")\n",
    "    with open(os.path.join(output_folder,\"cases.json\")) as fp:\n",
    "        json_data = json.load(fp)\n",
    "        gt_files, pred_files = json_data[\"gt_files\"], json_data[\"pred_files\"]\n",
    "        confidance_th = json_data[\"confidance_th\"]\n",
    "\n",
    "print(f\"Validating.. (Conf: {confidance_th})\")\n",
    "Validate(pred_files, gt_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
