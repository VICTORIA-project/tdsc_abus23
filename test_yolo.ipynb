{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "\n",
    "class Abus23DataLoader():\n",
    "    def __init__(self, dataset_path, labels_csv):\n",
    "        self.data = self.load_abus23(dataset_path, labels_csv)\n",
    "        self.dataset_path = dataset_path\n",
    "        self.used_data = self.data\n",
    "        self.cidx = 0\n",
    "        \n",
    "    def load_abus23(self, dataset_path, label_file):\n",
    "        dataset = pd.read_csv(os.path.join(dataset_path, label_file))\n",
    "        print(\"Dataset columns:\", dataset.columns)\n",
    "        return dataset\n",
    "    \n",
    "    def set_subset_ids(self, list_id = [], id_label = 'case_id'):\n",
    "        if list_id:\n",
    "            self.used_data = self.data[self.data[id_label].isin(list_id)]\n",
    "        \n",
    "    def get_data_entry(self, idx):    \n",
    "        return self.used_data.iloc[idx]\n",
    "    \n",
    "    def get_item(self, idx):\n",
    "        entry = self.get_data_entry(idx).to_dict()\n",
    "        output = {}\n",
    "        output[\"id\"] = entry['case_id']\n",
    "        if 'label' in entry:\n",
    "            output[\"class\"] =entry['label']\n",
    "        image_full_path = os.path.join(self.dataset_path, entry['data_path'].replace('\\\\','/'))\n",
    "        output[\"image\"] = sitk.ReadImage(image_full_path)\n",
    "        output[\"image_path\"] = image_full_path\n",
    "        if 'mask_path' in entry:\n",
    "            mask_full_path = os.path.join(self.dataset_path, entry['mask_path'].replace('\\\\','/'))\n",
    "            output[\"mask\"] = sitk.ReadImage(mask_full_path)\n",
    "            output[\"mask_path\"] = mask_full_path\n",
    "            \n",
    "        return output\n",
    "\n",
    "    def get_keys(self):\n",
    "        return self.used_data.columns.tolist()\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "       return self.get_item(idx)\n",
    "   \n",
    "    def __len__(self):\n",
    "        return len(self.used_data)\n",
    "   \n",
    "def get_validation_ids(val_file):\n",
    "    with open(val_file) as fp:\n",
    "        lines = fp.readlines()\n",
    "        #print([os.path.basename(i)for i in lines])\n",
    "        patients = set([int(os.path.basename(case).split('_')[0]) for case in lines])\n",
    "    return list(patients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def normalize_8bits(image: np.ndarray):\n",
    "    return (255.0 *(image - image.min()) / (image.max() - image.min())).astype(np.uint8)\n",
    "\n",
    "def get_slices(data, norm_fn = normalize_8bits):\n",
    "    data_array = sitk.GetArrayFromImage(data)\n",
    "    return [norm_fn(data_array[i, ...]) for i in range(len(data_array))]\n",
    "\n",
    "\n",
    "# Create the volume from slices\n",
    "\n",
    "def volume_from_slice(slices):\n",
    "    mask_3d = np.stack(slices)\n",
    "    output_mask = sitk.GetImageFromArray(mask_3d)\n",
    "    #castImageFilter = sitk.CastImageFilter()\n",
    "    #castImageFilter.SetOutputPixelType(sitk.sitkFloat32)\n",
    "    #img = castImageFilter.Execute(img)\n",
    "    \n",
    "    return output_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load a model\n",
    "class YOLOPredictor:\n",
    "    def __init__(self, model_file, conf_th = 0.5):\n",
    "        self.model = YOLO(model_file)  # pretrained YOLOv8n model\n",
    "        self.conf_th = conf_th\n",
    "        \n",
    "    def set_conf_th(self, conf_th = 0.5):\n",
    "        self.conf_th = conf_th\n",
    "        \n",
    "    def __call__(self, slice, conf_th=None):\n",
    "        return self.predict(slice, conf_th)\n",
    "        \n",
    "    def predict(self, slice, conf_th=None):\n",
    "        assert len(slice.shape) == 2\n",
    "        \n",
    "        if conf_th is None:\n",
    "            conf_th = self.conf_th\n",
    "        \n",
    "        cv2.imwrite(\"temp.png\", slice)\n",
    "        results = self.model(\"temp.png\", verbose=False)[0].cpu().numpy()\n",
    "        \n",
    "        slice_mask = np.zeros(slice.shape)\n",
    "        if results.masks is not None:\n",
    "            \n",
    "            pred_mask_data = results.masks.data\n",
    "            for i in range(len(pred_mask_data)):\n",
    "                \n",
    "                pred_box_conf = results.boxes[i].conf  # confidence score, (N, )\n",
    "                if pred_box_conf < conf_th:\n",
    "                    continue\n",
    "\n",
    "                m = cv2.resize(pred_mask_data[i, ...], dsize=(slice.shape[1], slice.shape[0])) # interpolation=cv2.INTER_CUBIC)\n",
    "                slice_mask = np.logical_or(slice_mask, m).astype(\"float32\")\n",
    "                \n",
    "        return slice_mask       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns: Index(['case_id', 'label', 'data_path', 'mask_path'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:44<00:00, 17.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ABUS 23\n",
    "dataset_path = \"datasets/Train\"\n",
    "label_file = \"labels.csv\"\n",
    "validation_file = \"datasets/abus23_25_png/val_seg.txt\"\n",
    "\n",
    "# Yolo model\n",
    "yolo_weights = \"/home/joel/abus23/runs/segment/train10/weights/best.pt\"\n",
    "\n",
    "# Output folder\n",
    "output_folder = os.path.join(\"results_masks\", \"abus23_25\", \"raw_stack_2\")\n",
    "\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "dataset = Abus23DataLoader(dataset_path, label_file)\n",
    "\n",
    "# Get validation cases\n",
    "val_ids = get_validation_ids(validation_file)\n",
    "dataset.set_subset_ids(val_ids)\n",
    "\n",
    "# Load yolo predictor\n",
    "yolo_predictor = YOLOPredictor(yolo_weights)\n",
    "\n",
    "# For each item in the dataset\n",
    "gt_files = []\n",
    "pred_files = []\n",
    "for item in tqdm(dataset):\n",
    "    \n",
    "        # Get image slice\n",
    "        image_slices = get_slices(item['image'])\n",
    "    \n",
    "        # Get predicted slices\n",
    "        yolo_masks_slices = [yolo_predictor(slice, conf_th=0.6) for slice in image_slices]\n",
    "\n",
    "        # Create 3D volum\n",
    "        mask_volum = volume_from_slice(yolo_masks_slices)\n",
    "        \n",
    "        # Copy metadata from predited image\n",
    "        mask_volum.CopyInformation(item['image'])\n",
    "        \n",
    "        # Save NRRD mask prediction\n",
    "        mask_file = os.path.join(output_folder, f\"{item['id']}.nrrd\")\n",
    "        sitk.WriteImage(mask_volum, mask_file, useCompression=True )\n",
    "        \n",
    "        # Save file names for evaluation\n",
    "        pred_files.append(mask_file)\n",
    "        gt_files.append(item['mask_path'])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TDSCABUS2023.Metrics import segmentation\n",
    "\n",
    "\n",
    "def Validate(pred_list, gt_list, cvs_pred_file = None, csv_gt_file = None):\n",
    "    \n",
    "    print(\"Segmentation:\")\n",
    "    print(\"------------------------------------------\")\n",
    "    \n",
    "    scores = {'DiceCoefficient': [], 'HDCoefficient': [], 'score': []}\n",
    "    for pred, gt in zip(pred_list, gt_list):\n",
    "        try:\n",
    "            result = segmentation.score_case(gt, pred)\n",
    "        except Exception as e:\n",
    "           result = {'DiceCoefficient': 0, 'HDCoefficient': 0, 'score': 0} #HD coefficient if fail?\n",
    "        print(\"Case:\", os.path.basename(pred), \"  Results:\",  result)\n",
    "        \n",
    "        for k, v in result.items():\n",
    "            scores[k].append(v)\n",
    "        \n",
    "    for k, values in scores.items():\n",
    "        values = np.array(values)\n",
    "        print(f\"\\n{k}:\")\n",
    "        print(f\"   - Min: {values.min():0.4f}\")\n",
    "        print(f\"   - Max: {values.max():0.4f}\")\n",
    "        print(f\"   - Mean: {values.mean():0.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['results_masks/abus23_25/raw_stack_2/7.nrrd', 'results_masks/abus23_25/raw_stack_2/9.nrrd', 'results_masks/abus23_25/raw_stack_2/10.nrrd', 'results_masks/abus23_25/raw_stack_2/14.nrrd', 'results_masks/abus23_25/raw_stack_2/22.nrrd', 'results_masks/abus23_25/raw_stack_2/25.nrrd', 'results_masks/abus23_25/raw_stack_2/31.nrrd', 'results_masks/abus23_25/raw_stack_2/39.nrrd', 'results_masks/abus23_25/raw_stack_2/53.nrrd', 'results_masks/abus23_25/raw_stack_2/61.nrrd', 'results_masks/abus23_25/raw_stack_2/62.nrrd', 'results_masks/abus23_25/raw_stack_2/66.nrrd', 'results_masks/abus23_25/raw_stack_2/67.nrrd', 'results_masks/abus23_25/raw_stack_2/74.nrrd', 'results_masks/abus23_25/raw_stack_2/75.nrrd', 'results_masks/abus23_25/raw_stack_2/80.nrrd', 'results_masks/abus23_25/raw_stack_2/87.nrrd', 'results_masks/abus23_25/raw_stack_2/89.nrrd', 'results_masks/abus23_25/raw_stack_2/90.nrrd', 'results_masks/abus23_25/raw_stack_2/99.nrrd']\n",
      "['datasets/Train/MASK/MASK_007.nrrd', 'datasets/Train/MASK/MASK_009.nrrd', 'datasets/Train/MASK/MASK_010.nrrd', 'datasets/Train/MASK/MASK_014.nrrd', 'datasets/Train/MASK/MASK_022.nrrd', 'datasets/Train/MASK/MASK_025.nrrd', 'datasets/Train/MASK/MASK_031.nrrd', 'datasets/Train/MASK/MASK_039.nrrd', 'datasets/Train/MASK/MASK_053.nrrd', 'datasets/Train/MASK/MASK_061.nrrd', 'datasets/Train/MASK/MASK_062.nrrd', 'datasets/Train/MASK/MASK_066.nrrd', 'datasets/Train/MASK/MASK_067.nrrd', 'datasets/Train/MASK/MASK_074.nrrd', 'datasets/Train/MASK/MASK_075.nrrd', 'datasets/Train/MASK/MASK_080.nrrd', 'datasets/Train/MASK/MASK_087.nrrd', 'datasets/Train/MASK/MASK_089.nrrd', 'datasets/Train/MASK/MASK_090.nrrd', 'datasets/Train/MASK/MASK_099.nrrd']\n"
     ]
    }
   ],
   "source": [
    "gt_files = [g.replace(\"DATA\", \"MASK\") for g in gt_files]\n",
    "print(pred_files)\n",
    "print(gt_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation:\n",
      "------------------------------------------\n",
      "Case: 7.nrrd   Results: {'DiceCoefficient': 0.4108192408071463, 'HDCoefficient': 293.4177908716511, 'score': -293.00697163084396}\n",
      "Case: 9.nrrd   Results: {'DiceCoefficient': 0.0, 'HDCoefficient': 230.59488285736091, 'score': -230.59488285736091}\n",
      "Case: 10.nrrd   Results: {'DiceCoefficient': 0.5383357066362257, 'HDCoefficient': 226.57890457851542, 'score': -226.0405688718792}\n",
      "Case: 14.nrrd   Results: {'DiceCoefficient': 0.13659776114277866, 'HDCoefficient': 340.74917461382057, 'score': -340.6125768526778}\n",
      "Case: 22.nrrd   Results: {'DiceCoefficient': 0.5968216750111011, 'HDCoefficient': 57.706152185014034, 'score': -57.109330510002934}\n",
      "Case: 25.nrrd   Results: {'DiceCoefficient': 0.6108740813545691, 'HDCoefficient': 45.221676218380054, 'score': -44.61080213702549}\n",
      "Case: 31.nrrd   Results: {'DiceCoefficient': 0, 'HDCoefficient': 0, 'score': 0}\n",
      "Case: 39.nrrd   Results: {'DiceCoefficient': 0.5201721162144022, 'HDCoefficient': 232.13358223230003, 'score': -231.61341011608562}\n",
      "Case: 53.nrrd   Results: {'DiceCoefficient': 0.2100306919642857, 'HDCoefficient': 200.90047287151916, 'score': -200.69044217955488}\n",
      "Case: 61.nrrd   Results: {'DiceCoefficient': 0.2605907619648637, 'HDCoefficient': 309.3121400785944, 'score': -309.0515493166295}\n",
      "Case: 62.nrrd   Results: {'DiceCoefficient': 0.5090851957617121, 'HDCoefficient': 109.47145746723207, 'score': -108.96237227147036}\n",
      "Case: 66.nrrd   Results: {'DiceCoefficient': 0.7194820219879716, 'HDCoefficient': 50.00999900019995, 'score': -49.290516978211976}\n",
      "Case: 67.nrrd   Results: {'DiceCoefficient': 0.3836228621350089, 'HDCoefficient': 150.70500987027606, 'score': -150.32138700814104}\n",
      "Case: 74.nrrd   Results: {'DiceCoefficient': 0.1378053104190706, 'HDCoefficient': 236.73825208444873, 'score': -236.60044677402965}\n",
      "Case: 75.nrrd   Results: {'DiceCoefficient': 0.9201153132664924, 'HDCoefficient': 109.07795377618706, 'score': -108.15783846292057}\n",
      "Case: 80.nrrd   Results: {'DiceCoefficient': 0.5843310426285837, 'HDCoefficient': 305.85944484354246, 'score': -305.27511380091386}\n",
      "Case: 87.nrrd   Results: {'DiceCoefficient': 0.539117290096585, 'HDCoefficient': 35.4400902933387, 'score': -34.900973003242115}\n",
      "Case: 89.nrrd   Results: {'DiceCoefficient': 0.8744031935424175, 'HDCoefficient': 20.024984394500787, 'score': -19.15058120095837}\n",
      "Case: 90.nrrd   Results: {'DiceCoefficient': 0.08434102764909673, 'HDCoefficient': 325.9279061387656, 'score': -325.8435651111165}\n",
      "Case: 99.nrrd   Results: {'DiceCoefficient': 0.6350133486732451, 'HDCoefficient': 51.82663407939975, 'score': -51.191620730726505}\n",
      "\n",
      "DiceCoefficient:\n",
      "   - Min: 0.0000\n",
      "   - Max: 0.9201\n",
      "   - Mean: 0.4336\n",
      "\n",
      "HDCoefficient:\n",
      "   - Min: 0.0000\n",
      "   - Max: 340.7492\n",
      "   - Mean: 166.5848\n",
      "\n",
      "score:\n",
      "   - Min: -340.6126\n",
      "   - Max: 0.0000\n",
      "   - Mean: -166.1512\n"
     ]
    }
   ],
   "source": [
    "Validate(pred_files, gt_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
